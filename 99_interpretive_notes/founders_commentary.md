# Founders’ Commentary and Interpretive Notes (Non-Normative)

## Status

This document is **non-normative**. It does not create requirements, prohibitions, or compliance obligations. In any conflict between this document and a standards document, the standards document controls.

## Purpose

Provide context, intent, and interpretive guidance to support long-term stewardship of the AI and quantum ethics standards corpus. The goal is continuity: helping future maintainers preserve meaning while adapting implementation details as technology and institutions evolve.

## Rationale Behind the Ethical Axioms

The ethical axioms were chosen to be:

- globally defensible across cultures and governance systems,
- compatible with human rights and due process traditions,
- operationalizable into testable requirements and auditable evidence,
- stable enough to anchor rapid technical change.

They are intentionally limited in number. A small axiom set reduces ambiguity and discourages “axiom shopping” (selecting whichever principle is convenient in a given moment).

## Why Risk-Based Governance Was Chosen

A risk-based approach was adopted because:

- harms differ dramatically by context, scale, and reversibility,
- uniform controls can be either performative (too weak for high-risk use) or impractical (too heavy for low-risk use),
- regulators and auditors commonly reason in tiers and controls.

Risk-based governance is not moral relativism. It is a mechanism for aligning safeguards to stakes, uncertainty, and exposure.

## Interpreting Tensions Between Principles

Ethical principles can come into tension in real deployments. Examples include:

- transparency versus security (disclosure can increase exploitation risk),
- privacy versus accountability (logging can create additional privacy risk),
- fairness versus accuracy (tradeoffs can exist depending on the domain and thresholds).

The corpus treats tension as a reason for explicit reasoning, evidence, and governance—not as a reason to discard a principle. When tensions arise, the intended interpretive posture is:

- make the tradeoff explicit,
- select controls that preserve dignity and remedy pathways,
- document residual risk and compensating safeguards,
- treat uncertainty with restraint in high-impact contexts.

## Warnings Against Common Misinterpretations

1. **“Ethics as marketing.”** Claims without evidence and scope boundaries undermine trust. Ethics language cannot substitute for audit artifacts.
2. **“Compliance as virtue.”** Certification indicates verified controls under a defined scope. It is not a guarantee of safety or moral legitimacy in all contexts.
3. **“Metrics as moral authority.”** Quantification supports governance decisions; it does not replace deliberation about legitimacy, coercion, or due process.
4. **“Secrecy as default.”** Legitimate security constraints exist, but secrecy without compensating oversight creates accountability gaps and enables abuse.
5. **“Outsourced responsibility.”** Third-party components do not transfer ethical responsibility away from operators and integrators.

## Guidance for Novel Technologies and New Contexts

When new capabilities or deployment contexts arise, stewards can preserve continuity by:

- grounding new standards in the existing axioms rather than inventing new principles as a first step,
- expanding definitions cautiously to avoid semantic drift,
- introducing new controls only with clear evidence artifacts and audit pathways,
- aligning tiering decisions to impact, scale, reversibility, opacity, and dual-use exposure,
- prioritizing mechanisms that keep contestability and remedy practical for affected parties.

## Institutional Continuity

The corpus is structured to support a standards institution rather than a static publication:

- ethical axioms anchor meaning,
- risk tiers scale safeguards,
- traceability links requirements to ethical intent and evidence,
- governance and change control prevent unilateral drift.

The enduring test of stewardship is not rhetorical alignment with values; it is whether the corpus continues to generate enforceable requirements that protect people under real incentives and real constraints.

